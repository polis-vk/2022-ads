# Отчет по бенчмаркам - Почернин Владислав

## Формулировка задания

- Написать **JMH** бенчмарки и сравнить время работы следующих алгоритмов:
    - Обычная сортировка вставками.
    - "Улучшенная" сортировка вставками.
    - Сортировка слиянием.
    - Быстрая сортировка.
    - Пирамидальная сортировка.
- Посмотреть на время работы алгоритмов на различных по длине входных массивах:
  - 100
  - 1 000
  - 10 000
  - 100 000
  - 1 000 000
- Результаты отобразить в отчете в формате *Markdown*, где:
  - Вставить (в виде *Markdown* кода) таблички с результатами бенчмарков. 
  - Отметить, какие алгоритмы на каких размерах массивов ведут себя лучше других.

## Теория

- **JMH** - Java Microbenchmark Harness - фреймворк для написания бенчмарков на языке Java.
- Казалось бы, можно просто считать время до и после работы алгоритма, но это будет **неправильно**.
  - JVM производит множество оптимизаций кода и данные, которые мы получим, могут быть *недостоверными*.
  - Кроме того, **JMH** предоставляет множество удобных настроек.
  - Наконец, **JMH** позволяет "прогреть" тестируемую функцию, несколько раз запустив её перед тестированием для применения всех оптимизаций JVM.

### Настройка JMH

- Метод, который будет тестироваться нужно пометить аннотацией `@Benchmark`.
- Чтобы код, который мы тестируем не был выброшен JVM, его нужно применить в некий `Blackhole`
- Приведем пример тестирования:
```java
@Benchmark
public void measureFibTailRec(Blackhole bh) {
    bh.consume(Fib.tailRecFib(dataLength));
}
```
- Также можно удобно задать параметр (например, чтобы выполнилось несколько бенчмарков для нескольких значений):
```java
@Param({"45", "60"})
private int datalength;
```

- Перед каждым прогоном бенчмарка будет выполняться инициализация из метода, помеченного аннотацией `@Setup`
```java
@Setup(value = Level.Invocation)
public void setUpInvocation() {
        array = IntStream.generate(() -> ThreadLocalRandom.current().nextInt()).limit(dataLength).boxed().toArray(Integer[]::new)
}
```

- Наконец, чтобы запустить тесты, нужно создать объект типа `Options` и запустить его:
```java
Options opt = new OptionsBuilder()
        .include(InsertionSortBench.class.getSimpleName())
        .forks(1)
        .jvmArgs("-Xms1G", "-Xmx1G")
        .warmupIterations(3)
        .measurementIterations(3)
        .build();

        new Runner(opt).run();
```
- Здесь мы можем увидеть следующие настройки:
  - `forks(1)` - вызов каждого теста в отдельном процессе.
  - `warmupIterations(3)` - три итерации "прогрева" функции перед тестированием.
  - `measurementIterations(3)` - каждый случай будет тестироваться по 3 раза и вернется среднее арифметическое.

## Результаты тестирования

